{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "${KERNEL_SPEC_DISPLAY_NAME}",
      "language": "${KERNEL_SPEC_LANGUAGE}",
      "name": "${KERNEL_SPEC_NAME}"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Copy of notebook1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHDGDO95YGC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gP3DAtiejRy"
      },
      "source": [
        "# Part 1\n",
        "**Q1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfYF1LgMLcNe",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "bb791892-629b-40cf-e62b-ef54a66e06dc"
      },
      "source": [
        "!rm *.csv\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Please load the raw csv data\")\n",
        "uploadedData = files.upload()\n",
        "filename = list(uploadedData)[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv': No such file or directory\n",
            "Please load the raw csv data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-534b7d11-a068-4b28-8655-c4dd1a807822\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-534b7d11-a068-4b28-8655-c4dd1a807822\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0be923ea52f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please load the raw csv data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploadedData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploadedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVCPiqj_L8ch"
      },
      "source": [
        "dataset = pd.read_csv(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT3gmNOXjtE9"
      },
      "source": [
        "# from google.colab import files /# use for debug only\n",
        "# outputPath = \"saved_file.csv\"\n",
        "# dataset.to_csv(outputPath)\n",
        "# files.download(outputPath) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwPJnat6gIfw"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXsL8-2YfA_m"
      },
      "source": [
        "**Q3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGJDTwmgpQrp"
      },
      "source": [
        "int_cols = {'AgeGroup', 'ConversatiosPerDay', 'DisciplineScore', 'HappinessScore', 'MedicalCarePerYear', 'NrCousins', 'StepsPerYear'}\n",
        "for col_name in int_cols:\n",
        "  dataset[col_name] = dataset[col_name].astype('Int64') # we chose 'Int64' becuase it is the only 'int' type which allows to use none vals\n",
        "\n",
        "\n",
        "dataset.Address = dataset.Address.astype('string')\n",
        "dataset.BloodType = dataset.BloodType.astype('category')\n",
        "dataset.DateOfPCRTest = dataset.DateOfPCRTest.astype('datetime64[ns]')\n",
        "dataset.Job = dataset.Job.astype('string')\n",
        "dataset.Self_declaration_of_Illness_Form = dataset.Self_declaration_of_Illness_Form.astype('string')\n",
        "dataset.Sex = dataset.Sex.astype('category')\n",
        "dataset.Virus = dataset.Virus.astype('category')\n",
        "dataset.SpreadLevel = dataset.SpreadLevel.astype('category')\n",
        "dataset.Risk = dataset.Risk.astype('category')\n",
        "\n",
        "dataset.dtypes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSGKQbiKgD4K"
      },
      "source": [
        "**before splitting our data to subsets, we first want to modify some of them a bit  (as part of Q 2.6)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7xPk17rj-w0"
      },
      "source": [
        "**the next few code-cells create catagorial columns based on numaric scale from catagorial columns based on string into**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2lh6AQkXDr_"
      },
      "source": [
        "dic_tmp = {'low': 1, 'medium': 2, 'high': 3}\n",
        "tmp_col = dataset.SpreadLevel.apply(lambda row: dic_tmp[row]).astype('Int64')\n",
        "dataset.insert(loc=dataset.columns.get_loc('SpreadLevel')+1, column='SpreadLevel_scala', value=tmp_col)\n",
        "tmp_col = dataset.Risk.apply(lambda row: dic_tmp[row]).astype('Int64')\n",
        "dataset.insert(loc=dataset.columns.get_loc('Risk')+1, column='Risk_scala', value=tmp_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-uwWU4ZUs6Y"
      },
      "source": [
        "tmp_col = dataset.CurrentLocation.apply(lambda row: np.nan if type(row) != str else row.split('\\'')[3]).astype(float)\n",
        "dataset.insert(loc=dataset.columns.get_loc('CurrentLocation')+1, column='y_location', value=tmp_col)\n",
        "tmp_col = dataset.CurrentLocation.apply(lambda row: np.nan if type(row) != str else row.split('\\'')[1]).astype(float)\n",
        "dataset.insert(loc=dataset.columns.get_loc('CurrentLocation')+1, column='x_location', value=tmp_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az3s7DyGWxPv"
      },
      "source": [
        "tmp_col = dataset.DateOfPCRTest.apply(lambda row: None if row is None else row.month).astype('Int64')\n",
        "dataset.insert(loc=dataset.columns.get_loc('DateOfPCRTest')+1, column='MonthOfPCRTest', value=tmp_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdo8w4VayCu"
      },
      "source": [
        "tmp_col = pd.cut(dataset['HouseholdExpenseParkingTicketsPerYear'],7,labels=[1,2,3,4,5,6,7]).astype('Int64')\n",
        "dataset.insert(loc=dataset.columns.get_loc('HouseholdExpenseParkingTicketsPerYear')+1, column='TicketsPerYearGroup', value=tmp_col) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08H-7o0hgOz"
      },
      "source": [
        "**Q 6**\n",
        "\n",
        "notice we did it before Q 4 in purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgavJX8UF6RB"
      },
      "source": [
        "# this code-cell creates new, more easy to use, columns based on Self_declaration_of_Illness_Form column\n",
        "tmp_col = dataset.Self_declaration_of_Illness_Form.apply(lambda row: [] if type(row) != str else sorted([x.strip() for x in row.split(';')]))\n",
        "dataset.insert(loc=dataset.columns.get_loc('Self_declaration_of_Illness_Form')+1, column='Symptoms_list', value=tmp_col)\n",
        "all_sym = set()\n",
        "for row in dataset.Symptoms_list:\n",
        "  all_sym = all_sym.union(row)\n",
        "\n",
        "for sym in all_sym:\n",
        "  tmp_col = dataset.Symptoms_list.apply(lambda row: sym in row)\n",
        "  dataset.insert(loc=dataset.columns.get_loc('Symptoms_list')+1, column=\"Is_having_\"+sym, value=tmp_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZ5AqLBKJeC"
      },
      "source": [
        "# this code-cell extracts the region from the address column\n",
        "def extract_only_city(s):\n",
        "  if (type(s) != str):\n",
        "    return None\n",
        "  s = s.split('\\r')[-1].split(',')[0]\n",
        "  for letter in s:\n",
        "    if letter.isdigit():\n",
        "      s = s.replace(letter,'')\n",
        "  return s.strip()\n",
        "\n",
        "tmp_col = dataset.Address.apply(lambda row: extract_only_city(row)).astype(str)\n",
        "dataset.insert(loc=dataset.columns.get_loc('Address')+1, column='Region', value=tmp_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F44SOn5vhJVM"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7BCrr1ljQn4"
      },
      "source": [
        "**we finished to modify the basic column we will work on so now we can split our data to test, train and validation subsets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeNk60ZjhXFR"
      },
      "source": [
        "**Q 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP5jMdWapv2Z"
      },
      "source": [
        "# Q 2.4 - spliting data to test, train and validation subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "tmp, test = train_test_split(dataset, test_size=0.2, random_state=12)\n",
        "train, validation =  train_test_split(tmp, test_size=0.25, random_state=12)\n",
        "\n",
        "# we are going to modify slices of dataset so pandas see it as 'SettingWithCopyWarning'. those msg are not relevant and annoying so...\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4nYm4PXhwme"
      },
      "source": [
        "(for Q 6 look at couple blocks back)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2X2Zqj8kbTC"
      },
      "source": [
        "##Missing data\n",
        "here we study our data, in particular its distribution, in order to choose how to fill missing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW6H5TpzkKNQ"
      },
      "source": [
        "**Q 7 - remove attributes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm4XTAGbs3IX"
      },
      "source": [
        "**Manual removing attributes with high percentage of divergence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DA3L9TFsiqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9da53b-6abd-4af4-91e4-c1b97fbfd7ae"
      },
      "source": [
        "high_divergence = [col for col in ['Region', 'Job'] if train[col].nunique()/train.shape[0] < 0.8]\n",
        "print(high_divergence)\n",
        "for col in high_divergence:\n",
        "  train.drop(col, axis='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Region', 'Job']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-cDrkdlXct"
      },
      "source": [
        "train.drop('Address', axis='columns', inplace=True) # due Region did not found useful..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sS1zwCnna5Q"
      },
      "source": [
        "**Manual removing attributes with high percentage of missing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djohgkix-Hbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1389b7-fce0-48c1-fcfe-f173b307870a"
      },
      "source": [
        "many_deficiencies = [col for col in train.columns if train[col].notnull().sum()/train.shape[0] < 0.8]\n",
        "print(many_deficiencies)\n",
        "for col in many_deficiencies:\n",
        "  train.drop(col, axis='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['PCR_11', 'PCR_15']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R2nkp4HiWbl"
      },
      "source": [
        "**Q 8 - here we fill missing cells of columns with normal distribution with their means**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8VPqhrTmW6T"
      },
      "source": [
        "for col in train:\n",
        "  if train[col].dtypes == 'Int64' or train[col].dtypes == float:\n",
        "    sns.histplot(train[col])\n",
        "    # sns.histplot(train[col], kde=True) \n",
        "    plt.grid()\n",
        "    plt.title(col + ' - examination of distribution')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKuYHgl5nl0S"
      },
      "source": [
        "# here we fill missing cells of columns with normal distribution with their means\n",
        "from statistics import mean\n",
        "\n",
        "for col_name in ['BMI', 'ConversatiosPerDay', 'DisciplineScore', 'HouseholdExpenseOnPresents',\n",
        "                 'PCR_7', 'PCR_72', 'PCR_89', 'SocialActivitiesPerDay', 'SportsPerDay']:\n",
        "  if train[col_name].dtypes == 'Int64':\n",
        "    m= train[col_name].fillna(round(train[col_name].mean()))\n",
        "    train[col_name] = train[col_name].fillna(m)\n",
        "    # also for test and validation\n",
        "    validation[col_name] = validation[col_name].fillna(m)\n",
        "    test[col_name] = test[col_name].fillna(m)\n",
        "  else:\n",
        "    m= train[col_name].fillna(train[col_name].mean())\n",
        "    train[col_name] = train[col_name].fillna(m)\n",
        "    # also for test and validation\n",
        "    validation[col_name] = validation[col_name].fillna(m)\n",
        "    test[col_name] = test[col_name].fillna(m)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmvT7MBt567K"
      },
      "source": [
        "# here we fill missing cells of columns with non-normal distribution with their median (which more meaning in this case than using mean)\n",
        "for col_name in ['AgeGroup', 'HappinessScore', 'HouseholdExpenseOnSocialGames', 'HouseholdExpenseParkingTicketsPerYear',\n",
        "                 'MedicalCarePerYear', 'NrCousins', 'PCR_19', 'PCR_95', 'StepsPerYear']:\n",
        "  m = train[col_name].median()\n",
        "  train[col_name] = train[col_name].fillna(m)\n",
        "  validation[col_name] = validation[col_name].fillna(m)\n",
        "  test[col_name] = test[col_name].fillna(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaafWljAbUwx"
      },
      "source": [
        "# notice we choose to fill only numerical data with good studiable distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-xlAWHWO5O_"
      },
      "source": [
        "## Outlier Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pku_i3vjd3l"
      },
      "source": [
        "**Q 9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D1ohEZMjZBb"
      },
      "source": [
        "col_list = [col for col in train.columns[1:-5] if train[col].dtypes == 'Int64' or train[col].dtypes == float]\n",
        "for col in col_list:\n",
        "  ax = sns.boxplot(x=train[col], y=train['Virus'])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcbCls6WjlrQ"
      },
      "source": [
        "**Q 10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHEDEydmPKwp"
      },
      "source": [
        "**Z-score (only on data with close-to-normal distribution)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpKYOVzTVyYN"
      },
      "source": [
        "for col in ['ConversatiosPerDay', 'BMI', 'HouseholdExpenseOnPresents', 'PCR_19', 'PCR_7',\n",
        "            'PCR_72', 'PCR_89', 'SocialActivitiesPerDay', 'SocialMediaPerDay']:\n",
        "  if train[col_name].dtypes == 'Int64':\n",
        "    m = round(train[col].mean())\n",
        "  else:\n",
        "    m = train[col].mean()  \n",
        "  tmp_col = (train[col] - m)/train[col].std(ddof=0)\n",
        "  for index, row in train.iterrows():\n",
        "    if train[col][index] is not np.nan and tmp_col[index] >= 3:\n",
        "      train[col][index] = m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf5XuRoqHtTM"
      },
      "source": [
        "**BoxPlots - Finding Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjqODPHfMOL-"
      },
      "source": [
        "# manully correcting outliner\n",
        "m = train['DisciplineScore'].median() \n",
        "for index, row in train.iterrows():\n",
        "    if train['DisciplineScore'][index] < 0 or train['DisciplineScore'][index] > 10:# outlier \n",
        "      train['DisciplineScore'][index] = m \n",
        "ax = sns.boxplot(x=train['DisciplineScore'], y=train['Virus'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA3vhKwSviT3"
      },
      "source": [
        "col_list = [col for col in train.columns[1:-5] if train[col].dtypes == 'Int64' or train[col].dtypes == float]\n",
        "print(col_list)\n",
        "for i in col_list:\n",
        "  q1 = train[i].quantile(0.25)\n",
        "  q3 = train[i].quantile(0.75)\n",
        "  iqr = q3-q1 #Interquartile range\n",
        "  fence_low  = q1-1.5*iqr\n",
        "  fence_high = q3+1.5*iqr\n",
        "  m = train[i].median()\n",
        "  train[i] = train[i].apply(lambda row: m if (pd.isnull(row) or row < fence_low or row > fence_high) else row)\n",
        "\n",
        "  # this is for test and validation also. outline the data according to test \n",
        "  test[i] = test[i].apply(lambda row: m if (pd.isnull(row) or row < fence_low or row > fence_high) else row)\n",
        "  validation[i] = validation[i].apply(lambda row: m if (pd.isnull(row) or row < fence_low or row > fence_high) else row)\n",
        "    \n",
        "  ax = sns.boxplot(x=train[i], y=train['Virus'])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbPcccb9Tuc9"
      },
      "source": [
        "**Data Transformation - Normalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlKnW75ypqW7"
      },
      "source": [
        "**Q 11**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag8PH5rFSjr2"
      },
      "source": [
        "sns.histplot(train.StepsPerYear) \n",
        "plt.grid()\n",
        "plt.title('StepsPerYear - examination of distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSKJ3UQpaors"
      },
      "source": [
        "try to detect which normalization is better in case of this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY5fxs6bT3jc"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "steps_copy = train[['StepsPerYear']].copy() # we used copy to show we checked this option, but we chosed the next option which modify with\n",
        "x_scaled = min_max_scaler.fit_transform(steps_copy)\n",
        "steps_copy = x_scaled\n",
        "\n",
        "sns.histplot(steps_copy) \n",
        "plt.grid()\n",
        "plt.title('StepsPerYear - examination of distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIb0qg8JZydR"
      },
      "source": [
        "train['StepsPerYear'] = (train['StepsPerYear'] - train['StepsPerYear'].median())/train['StepsPerYear'].std(ddof=0)\n",
        "\n",
        "sns.histplot(train.StepsPerYear) \n",
        "plt.grid()\n",
        "plt.title(col + ' - examination of distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUj8Zi2sMPXl"
      },
      "source": [
        "**Q 12**\n",
        "\n",
        "normalize all numeric data (not category)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxMtYb_MSPa"
      },
      "source": [
        "for col in train.columns:\n",
        "  if train[col].dtypes == float or (train[col].dtypes == 'Int64' and train[col].unique().size > 25):\n",
        "    min = train[col].min()\n",
        "    max = train[col].max()\n",
        "    train[col] = min_max_scaler.fit_transform(train[[col]])\n",
        "\n",
        "    # this is for test and validation also. outline the data according to test \n",
        "    validation[col] =  validation[col].apply(lambda row: (row-min)/(max-min))\n",
        "    test[col] = test[col].apply(lambda row: (row-min)/(max-min))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh40TFbSB32F"
      },
      "source": [
        "**we rerun distribution plots for all attributes to see how they changed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m77HfDBpsD66"
      },
      "source": [
        "for col in train:\n",
        "  if train[col].dtypes == 'Int64' or train[col].dtypes == float:\n",
        "    sns.histplot(train[col])\n",
        "    plt.grid()\n",
        "    plt.title(col + ' - examination of distribution')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdWD8sdorm3T"
      },
      "source": [
        "# Part 3 - Feature Selecting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRcm7ANHrveM"
      },
      "source": [
        "**Q 13 - correlation table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn89wHZAtHFo"
      },
      "source": [
        "train_copy = train.copy()\n",
        "catagory_col = [col for col in train_copy.columns if 'Is_having_' in col]\n",
        "catagory_col.extend(['Sex', 'BloodType'])\n",
        "for col in catagory_col:\n",
        "  dic_tmp = {}\n",
        "  counter = 0\n",
        "  for t in train_copy[col].unique():\n",
        "    counter = counter+1\n",
        "    dic_tmp[t] = counter\n",
        "  train_copy[col] = train_copy[col].apply(lambda row: dic_tmp[row]).astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i851DSc9yZD6"
      },
      "source": [
        "features = train_copy.columns.to_list()\n",
        "# print(train_copy.columns)\n",
        "f = plt.figure(figsize=(20, 15))\n",
        "plt.matshow(train_copy.corr(), fignum=f.number)\n",
        "plt.xticks(range(train_copy.select_dtypes(['number']).shape[1]), train_copy.select_dtypes(['number']).columns, fontsize=14, rotation=90)\n",
        "plt.yticks(range(train_copy.select_dtypes(['number']).shape[1]), train_copy.select_dtypes(['number']).columns, fontsize=14)\n",
        "cb = plt.colorbar()\n",
        "cb.ax.tick_params(labelsize=14)\n",
        "_ = plt.title('Correlation Matrix', fontsize=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZLYJdBmH9Jm"
      },
      "source": [
        "train.corr()\n",
        "corr = train.corr()\n",
        "kot = corr[corr>=.85]\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(kot, cmap=\"Greens\")\n",
        "plt.show()\n",
        "print(train['PCR_83'].corr(train['PCR_45']))\n",
        "print(train['HouseholdExpenseOnSocialGames'].corr(train['SportsPerDay']))\n",
        "print(train['SocialActivitiesPerDay'].corr(train['HouseholdExpenseOnSocialGames']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZFTTEsz5qs"
      },
      "source": [
        "# manually removing att with high corollation\n",
        "train.drop('NrCousins', axis='columns', inplace=True)\n",
        "train.drop('PCR_83', axis='columns', inplace=True)\n",
        "train.drop('SocialActivitiesPerDay', axis='columns', inplace=True)\n",
        "train.drop('SportsPerDay', axis='columns', inplace=True)\n",
        "train.drop('StepsPerYear', axis='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8chPywSXDvC"
      },
      "source": [
        "**Q 14**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLVZboZ85o4U"
      },
      "source": [
        "# explore the connections of targets attributes\n",
        "train_copy = train[['Virus', 'SpreadLevel_scala', 'Risk_scala']]\n",
        "train_copy=train_copy.dropna()\n",
        "train_copy.SpreadLevel_scala = train_copy.SpreadLevel_scala.astype(int)\n",
        "train_copy.Risk_scala = train_copy.Risk_scala.astype(int)\n",
        "sns.jointplot(data=train_copy, x='SpreadLevel_scala', y='Risk_scala', hue='Virus')\n",
        "plt.grid()\n",
        "plt.title('SpreadLevel_scala - Risk_scala joint distribution')\n",
        "plt.show()\n",
        "# note: we did not found this plot useful  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYe5fcv0sLXx"
      },
      "source": [
        "**Filter methods**\n",
        "\n",
        "we select according to joint attributes distribution plots "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYjCIX-fn5W-"
      },
      "source": [
        "from itertools import combinations\n",
        "all_combos = [x for x in (combinations(train.columns[:-5],2))]\n",
        "print(all_combos)\n",
        "print(len(all_combos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1BI-akAeyQm"
      },
      "source": [
        "# manually explore joint attributes distribution\n",
        "def joint_att_distribution(start, finish):\n",
        "  for pair in all_combos[start:finish]:\n",
        "    col1 = pair[0]\n",
        "    col2 = pair[1]\n",
        "    #   continue\n",
        "    if (train[col1].dtypes == 'Int64' or train[col1].dtypes == float) and (train[col2].dtypes == 'Int64' or train[col2].dtypes == float):\n",
        "      for label in ['Virus', 'Risk', 'SpreadLevel']:\n",
        "        train_copy = train[[col1, col2, 'Virus', 'Risk', 'SpreadLevel']]\n",
        "        train_copy.dropna\n",
        "        if train_copy[col1].dtypes == 'Int64': # apperently this specific plot does not work with 'Int64' so i need to convert it to simple int\n",
        "          train_copy[col1] = train_copy[col1].astype(int)\n",
        "        if train_copy[col2].dtypes == 'Int64':\n",
        "          train_copy[col2] = train_copy[col2].astype(int) \n",
        "        sns.jointplot(data=train_copy, x=col1, y=col2, hue=label)\n",
        "        plt.grid()\n",
        "        plt.title(col1 + ' - ' + col2 + ' joint distribution')\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLv4gtrGqhNw"
      },
      "source": [
        "joint_att_distribution(0, 400) # too much to print in one code-cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPYSZ_MUqjbw"
      },
      "source": [
        "joint_att_distribution(400, 800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxdxeB7yql4v"
      },
      "source": [
        "joint_att_distribution(800, 1200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgAr5bZnrDQT"
      },
      "source": [
        "joint_att_distribution(1200, 1485)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7iynz-bSUjB"
      },
      "source": [
        "# now we try the same thing but with the catagorial column (after modify them inorder to run the same code)\n",
        "train_copy = train.copy()\n",
        "catagory_col = [col for col in train_copy.columns if 'Is_having_' in col]\n",
        "catagory_col.extend(['Sex', 'BloodType'])\n",
        "print(catagory_col)\n",
        "for col in catagory_col:\n",
        "  dic_tmp = {}\n",
        "  counter = 0\n",
        "  for t in train_copy[col].unique():\n",
        "    counter = counter+1\n",
        "    dic_tmp[t] = counter\n",
        "  train_copy[col] = train_copy[col].apply(lambda row: dic_tmp[row]).astype(float)\n",
        "\n",
        "for col1 in catagory_col:\n",
        "  for col2 in train_copy.columns[1:-5]:\n",
        "    if col1 != col2 and (train_copy[col2].dtypes == 'Int64' or train_copy[col2].dtypes == float):\n",
        "      for label in ['Virus', 'Risk', 'SpreadLevel']:\n",
        "        train_copy2 = train_copy[[col1, col2, 'Virus', 'Risk', 'SpreadLevel']]\n",
        "        train_copy2.dropna(inplace=True)\n",
        "        if train_copy2[col2].dtypes == 'Int64':\n",
        "          train_copy2[col2] = train_copy2[col2].astype(int) \n",
        "        sns.jointplot(data=train_copy2, x=col1, y=col2, hue=label)\n",
        "        plt.grid()\n",
        "        plt.title(col1 + ' - ' + col2 + ' joint distribution')\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o73Rh84u-GUS"
      },
      "source": [
        "**Wrapper method - forward**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH2vclf5pgVn"
      },
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "training_model = LinearRegression()\n",
        "\n",
        "col_names = [col for col in train.columns if train[col].dtypes == 'Int64' or train[col].dtypes == float or train[col].dtypes == bool]\n",
        "\n",
        "train_copy = train.copy()\n",
        "dic_tmp = {}\n",
        "counter = 0\n",
        "for t in train.Virus.unique():\n",
        "  counter = counter+1\n",
        "  dic_tmp[t] = counter\n",
        "train_copy['Virus_numeric'] = train_copy.Virus.apply(lambda row: dic_tmp[row]).astype(int)\n",
        "train_copy['Is_covid'] = train_copy.Virus.apply(lambda row: 1 if row == 'covid' else 0).astype(int)\n",
        "\n",
        "col_names.extend(['Virus_numeric', 'Is_covid'])\n",
        "\n",
        "train_copy = train_copy[col_names].dropna()\n",
        "\n",
        "X =  train_copy[col_names[:-4]]\n",
        "sfs = SFS(training_model, k_features=8, forward=True, floating=False)\n",
        "\n",
        "print(col_names)\n",
        "train_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMPVxB9t1VTc"
      },
      "source": [
        "y =  train_copy.Risk_scala\n",
        "\n",
        "sfs.fit(X, y)\n",
        "\n",
        "top_att1 = pd.DataFrame(sfs.subsets_).transpose()\n",
        "top_att1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbLGXJTX5HOi"
      },
      "source": [
        "y =  train_copy.SpreadLevel_scala\n",
        "\n",
        "sfs.fit(X, y)\n",
        "\n",
        "top_att2 = pd.DataFrame(sfs.subsets_).transpose()\n",
        "top_att2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpDHfM18lYZ2"
      },
      "source": [
        "y =  train_copy.Is_covid\n",
        "\n",
        "sfs.fit(X, y)\n",
        "\n",
        "top_att3 = pd.DataFrame(sfs.subsets_).transpose()\n",
        "top_att3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0UaRJ9Oss-C"
      },
      "source": [
        "y =  train_copy.Virus_numeric\n",
        "\n",
        "sfs.fit(X, y)\n",
        "\n",
        "top_att4 = pd.DataFrame(sfs.subsets_).transpose()\n",
        "top_att4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnpMrnEus0qO"
      },
      "source": [
        "chosen_att = []\n",
        "chosen_att.extend(top_att1.feature_names[6])\n",
        "chosen_att.extend(top_att2.feature_names[6])\n",
        "chosen_att.extend(top_att3.feature_names[6])\n",
        "chosen_att.extend(top_att4.feature_names[6])\n",
        "chosen_att = list(set(chosen_att))\n",
        "chosen_att.sort()\n",
        "print(chosen_att)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvT0XtR_wxka"
      },
      "source": [
        "**Wrapper method - backward**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk-y63UFJZIt"
      },
      "source": [
        "col_to_check =  [col for col in col_names if col not in chosen_att]\n",
        "training_model = KNeighborsClassifier(n_neighbors=30)\n",
        "\n",
        "worst_att_list = []\n",
        "for i in range(8):\n",
        "  worst_score = float('inf')\n",
        "  curr_worst = ''\n",
        "  for col in col_to_check[:-4]:\n",
        "    curr_cols = col_to_check.copy()\n",
        "    curr_cols.remove(col)\n",
        "    X = train_copy[curr_cols]\n",
        "    y = train_copy.Is_covid\n",
        "    sbs = SFS(training_model, forward=False, floating=False, k_features=len(curr_cols))\n",
        "    sbs = sbs.fit(X, y)\n",
        "    curr_score = pd.DataFrame(sbs.subsets_).transpose().iloc(0)[0][0]\n",
        "    if worst_score > curr_score:\n",
        "      worst_score = curr_score\n",
        "      curr_worst = col\n",
        "  worst_att_list.append(curr_worst)\n",
        "  col_to_check.remove(curr_worst)\n",
        "\n",
        "worst_att_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDbiRZUFOu11"
      },
      "source": [
        "**Bi-Variate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrxlyJTRlbvz"
      },
      "source": [
        "# manually explore attributes distribution with the targets attributes\n",
        "for col in train.columns:\n",
        "  if train[col].dtypes != object and train[col].unique().size < 25 :\n",
        "    for label in ['Virus', 'Risk', 'SpreadLevel']:\n",
        "      new_plot = pd.crosstab(train[col], train[label])\n",
        "      new_plot.plot(kind='bar', stacked=True,  grid=False)\n",
        "      plt.grid()\n",
        "      plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6notP59YggE"
      },
      "source": [
        "**Q 15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xXxDULhdUcO"
      },
      "source": [
        "data = []\n",
        "possible_col = [x for x in dataset.columns if 'Is_having' not in x and '_scala' not in x]\n",
        "\n",
        "chosen_att.append('Self_declaration_of_Illness_Form') # replacing all 'Is_having...'\n",
        "correlation_remove = ['NrCousins', 'SportsPerDay', 'SocialActivitiesPerDay', 'StepsPerYear','PCR_83']\n",
        "low_num_samples = ['PCR_11', 'PCR_15']\n",
        "manually_unwanted = ['Address', 'CurrentLocation', 'Job']\n",
        "manually_probably_not_intresting = ['StudingPerDay', 'PCR_45']\n",
        "manually_remove = ['Region', 'TicketsPerYearGroup', 'MonthOfPCRTest', 'Symptoms_list', 'x_location', 'y_location']\n",
        "label_tags = ['Virus', 'SpreadLevel', 'Risk']\n",
        "\n",
        "for col in possible_col:\n",
        "  if col in manually_remove:\n",
        "    continue\n",
        "  elif col in worst_att_list:\n",
        "    data.append([col, 'N', 'wrapper method - backward'])\n",
        "  elif col in manually_unwanted:\n",
        "    data.append([col, 'N', 'did not found useful information in data'])\n",
        "  elif col in low_num_samples:\n",
        "    data.append([col, 'N', 'low nomber of samples'])\n",
        "  elif col in correlation_remove:\n",
        "    data.append([col, 'N', 'high correlation with another attribute'])\n",
        "  elif col in manually_probably_not_intresting:\n",
        "    data.append([col, 'N', 'manually removed due lack of useful data in our study (filter method and bi-variate)'])\n",
        "  elif col in chosen_att:\n",
        "    data.append([col, 'Y', 'wrapper method - forward'])\n",
        "  elif col in label_tags:\n",
        "    data.append([col, 'Y', 'target'])\n",
        "  else:\n",
        "    data.append([col, 'Y', 'leftovers - left due to lack of clear decision'])\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['Attribute', 'Take_or_throw', 'reason'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ5LuM6uCPb2"
      },
      "source": [
        "thrown_col = df[df.Take_or_throw=='N'].Attribute.to_list()\n",
        "print(len(thrown_col), \"not taken:\")\n",
        "print(thrown_col)\n",
        "taken_col = df[df.Take_or_throw=='Y'].Attribute.to_list()\n",
        "print(len(taken_col), \"taken:\")\n",
        "print(taken_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9n5rZKi6jlr"
      },
      "source": [
        "**Q 16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-TpjxgS5jrb"
      },
      "source": [
        "# # not sure if needed or not...\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# tmp, test = train_test_split(dataset, test_size=0.2, random_state=12)\n",
        "# train, validation =  train_test_split(tmp, test_size=0.25, random_state=12)\n",
        "\n",
        "# # we are going to modify slices of dataset so pandas see it as 'SettingWithCopyWarning'. those msg are not relevant and annoying so...\n",
        "# pd.options.mode.chained_assignment = None  # default='warn'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPvDKTx2gVgU"
      },
      "source": [
        "train_modify = train[taken_col].copy()\n",
        "validation_modify = validation[taken_col].copy()\n",
        "test_modify = test[taken_col].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WekLqoiohrUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fddf796a-e8ee-41b1-beca-54c727b87bdf"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "outputPath = \"train_file.csv\"\n",
        "train.to_csv(outputPath)\n",
        "files.download(outputPath) \n",
        "\n",
        "outputPath = \"train_modify_file.csv\"\n",
        "train_modify.to_csv(outputPath)\n",
        "files.download(outputPath) \n",
        "\n",
        "outputPath = \"validation.csv\"\n",
        "validation.to_csv(outputPath)\n",
        "files.download(outputPath) \n",
        "\n",
        "outputPath = \"validation_modify_file.csv\"\n",
        "validation_modify.to_csv(outputPath)\n",
        "files.download(outputPath) \n",
        "\n",
        "outputPath = \"test_file.csv\"\n",
        "test.to_csv(outputPath)\n",
        "files.download(outputPath) \n",
        "\n",
        "outputPath = \"test_modify_file.csv\"\n",
        "test_modify.to_csv(outputPath)\n",
        "files.download(outputPath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6b5cf8fb-00df-4017-a446-a33d23e3b747\", \"train_file.csv\", 1418532)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_19b75746-d535-49a1-8d20-a4230d5c7002\", \"train_modify_file.csv\", 791666)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6f5169ab-3631-4aae-a4ec-f4d7ad580654\", \"validation.csv\", 565395)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_aa325e5e-745d-49db-b749-c625d942ba96\", \"validation_modify_file.csv\", 260901)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_98df3d88-627b-4871-aa9d-11de1b83728e\", \"test_file.csv\", 565098)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_36beb4b4-ab85-401d-aaad-f79f77c26938\", \"test_modify_file.csv\", 260884)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTewAjFZ6msH"
      },
      "source": [
        "# TYOTA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFlh1-hbYEK"
      },
      "source": [
        "# # TOYOTA - for isolte running and mini tests\n",
        "# col1 = 'PCR_46'\n",
        "# col2 = 'PCR_32'\n",
        "# if (train[col1].dtypes == 'Int64' or train[col1].dtypes == float) and col1 != col2 and (train[col2].dtypes == 'Int64' or train[col2].dtypes == float):\n",
        "#   for label in ['Virus', 'Risk', 'SpreadLevel']:\n",
        "#     train_copy = train[[col1, col2, 'Virus', 'Risk', 'SpreadLevel']]\n",
        "#     train_copy.dropna(inplace=True)\n",
        "#     if train_copy[col1].dtypes == 'Int64': # apperently this specific plot does not work with 'Int64' so i need to convert it to simple int\n",
        "#       train_copy[col1] = train_copy[col1].astype(int)\n",
        "#     if train_copy[col2].dtypes == 'Int64':\n",
        "#       train_copy[col2] = train_copy[col2].astype(int) \n",
        "#     sns.jointplot(data=train_copy, x=col1, y=col2, hue=label)\n",
        "#     plt.grid()\n",
        "#     plt.title(col1 + ' - ' + col2 + ' joint distribution')\n",
        "#     plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUQCuvOKO_Z6"
      },
      "source": [
        "# # TOYOTA - for isolte running and mini tests\n",
        "# for col1 in ['PCR_7', 'PCR_45', 'PCR_76', 'PCR_93']:\n",
        "#   for col2 in train.columns[1:-5]:\n",
        "\n",
        "#     if (train[col1].dtypes == 'Int64' or train[col1].dtypes == float) and col1 != col2 and (train[col2].dtypes == 'Int64' or train[col2].dtypes == float):\n",
        "#       for label in ['Virus', 'Risk', 'SpreadLevel']:\n",
        "#         train_copy = train[[col1, col2, 'Virus', 'Risk', 'SpreadLevel']]\n",
        "#         train_copy.dropna(inplace=True)\n",
        "#         if train_copy[col1].dtypes == 'Int64': # apperently this specific plot does not work with 'Int64' so i need to convert it to simple int\n",
        "#           train_copy[col1] = train_copy[col1].astype(int)\n",
        "#         if train_copy[col2].dtypes == 'Int64':\n",
        "#           train_copy[col2] = train_copy[col2].astype(int) \n",
        "#         sns.jointplot(data=train_copy, x=col1, y=col2, hue=label)\n",
        "#         plt.grid()\n",
        "#         plt.title(col1 + ' - ' + col2 + ' joint distribution')\n",
        "#         plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}